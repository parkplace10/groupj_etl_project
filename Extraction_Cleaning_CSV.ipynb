{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"Resources\\Site_2_Projections\\Site_2_W16_projections.csv\"\n",
    "four44_df = pd.read_csv(csv_file)\n",
    "\n",
    "four44_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Fanduel uniform scoring system to Fantasy Sharks raw predictions and creating a new column with the results\n",
    "four44_df['Site 2'] = four44_df['Pass Yds'] * .04 + four44_df['Rush Yds'] * .1 + four44_df['Rec Yds'] * .1 + \\\n",
    "four44_df['Pass TD'] * 4 + four44_df['Rush TD'] * 6 + four44_df['Rec TD'] * 6 + four44_df['Rec'] * .5 + four44_df['INT'] * -1 \\\n",
    "+ four44_df['Fum'] * -2\n",
    "\n",
    "four44_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unneeded columns\n",
    "four44_df = four44_df.drop([\n",
    " 'PID',\n",
    " 'Pos',\n",
    " 'Team',\n",
    " 'Opp',\n",
    " 'aFPA',\n",
    " 'aFPA Rk',\n",
    " 'FFPts',\n",
    " 'Comp',\n",
    " 'Pass Att',\n",
    " 'Pass Yds',\n",
    " 'Pass TD',\n",
    " 'INT',\n",
    " 'Rush Att',\n",
    " 'Rush Yds',\n",
    " 'Rush TD',\n",
    " 'Rec',\n",
    " 'Rec Yds',\n",
    " 'Rec TD',\n",
    " 'Pa1D',\n",
    " 'Ru1D',\n",
    " 'Rec1D',\n",
    " 'Fum',\n",
    " 'XP',\n",
    " 'FG',\n",
    " 'Grade'], axis=1)\n",
    "\n",
    "# Rename player column to \"Name\"\n",
    "four44_df.rename(columns = {\"Player\": \"Name\"}, inplace = True)\n",
    "\n",
    "four44_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"Resources\\Fantasy_Sharks_Projections\\W16_Projections.csv\"\n",
    "\n",
    "#Resources\\Fantasy_Sharks_Projections\\fantasysharks_W16_Projections.csv\n",
    "sharks_df = pd.read_csv(csv_file)\n",
    "sharks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the name into 2 seperate columns\n",
    "sharks_df[['Last Name','First Name']] = sharks_df['Name'].str.split(', ',expand=True)\n",
    "sharks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombine names into one column in the order of First Last\n",
    "sharks_df['Name'] = sharks_df['First Name'].str.cat(sharks_df['Last Name'],sep=\" \")\n",
    "sharks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Fanduel uniform scoring system to Fantasy Sharks raw predictions and creating a new column with the results\n",
    "sharks_df['Fantasy Sharks'] = sharks_df['Yards'] * .04 + sharks_df['Yards.1'] * .1 + sharks_df['Yards.2'] * .1 + \\\n",
    "sharks_df['TD'] * 4 + sharks_df['TD.1'] * 6 + sharks_df['TD.2'] * 6 + sharks_df['Rec'] * .5 + sharks_df['Int'] * -1 \n",
    "\n",
    "sharks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks_df = sharks_df.drop(['ID', 'Rank', 'First Name', 'Last Name', 'Comp', 'Yards', 'TD', 'TD.1', \n",
    "'TD.2', 'Int', 'Att', 'Yards.1', 'Yards.2', 'Rec', 'Fantasy Points'], axis=1)\n",
    "sharks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = sharks_df.merge(four44_df, on=['Name'], sort=False)\n",
    "\n",
    "combined_df.round({'Fantasy Sharks': 1, 'Site 2': 1})\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "combined_df = combined_df[['Season', 'Week', 'Name', 'Pos', 'Team', 'Opp', 'Fantasy Sharks', 'Site 2']]\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"W16_Combined_Projections.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
